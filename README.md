# P2M_Image_Captioning
This project aims to generate captions for images using a pre-trained image captioning model. The model used in this project is based on the VisionEncoderDecoderModel from the Hugging Face transformers library and specifically uses the ViT-GPT2 architecture.

# Model Deployment
The trained model has been deployed using Gradio and Hugging Face's model hosting service. You can access the deployed model by following this link. The model checkpoint and associated files can be found on the Hugging Face model repository.
